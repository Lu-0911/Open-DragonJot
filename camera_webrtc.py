import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import av
import numpy as np
import torch
from pathlib import Path
from ultralytics import YOLO
import cv2

# ---------- ä½ çš„å¸¸é‡/å·¥å…·å‡½æ•°ï¼ˆä» app.py æ‹·è¿‡æ¥ï¼‰ ----------
from app import (                     # ç›´æ¥å¤ç”¨ app.py é‡Œå·²å®ç°çš„ä¸œè¥¿
    DRAGON_KEYPOINT_NAMES,
    DRAGON_SKELETON,
    DEFAULT_NODE_COLORS,
    DEFAULT_LINE_COLOR,
    gpu_monitor,
    get_params,
    put_chinese_text,
    classify_action,
    build_class_inputs,
    EMAFilter,
    KalmanFilterWrapper
)

# ---------- WebRTC å›è°ƒ ----------
def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    img = frame.to_ndarray(format="bgr24")          # æµè§ˆå™¨é‡‡é›†åˆ°çš„å¸§
    params = get_params()                           # è¯»å–ä½ åœ¨ä¾§è¾¹æ é‡Œä¿å­˜çš„å‚æ•°
    device = params['device']

    # 1. åŠ è½½æ¨¡å‹ï¼ˆç¼“å­˜é¿å…æ¯æ¬¡é‡è½½ï¼‰
    if "model_person" not in st.session_state:
        st.session_state.model_person = YOLO(params['person_model']).to(device)
    if "model_dragon" not in st.session_state:
        st.session_state.model_dragon = YOLO(params['dragon_model']).to(device)
    if "classify_model_obj" not in st.session_state and params['classify']:
        ckpt = torch.load(Path("model")/params['classify_model'], map_location=device)
        from app import PoseCNN
        model = PoseCNN(num_classes=len(ckpt['classes'])).to(device)
        model.load_state_dict(ckpt['model_state_dict'])
        model.eval()
        st.session_state.classify_model_obj = model
        st.session_state.classes = ckpt['classes']

    # 2. æ¨ç†
    person_results = st.session_state.model_person(img, conf=params['confs'][0], verbose=False)
    dragon_results = st.session_state.model_dragon(img, conf=params['confs'][1], verbose=False)

    # 3. ç”»å…³é”®ç‚¹ + éª¨æ¶ï¼ˆç›´æ¥å¤ç”¨ä½  app.py é‡Œçš„ä»£ç ï¼‰
    out = img.copy()
    if person_results:
        out = person_results[0].plot(boxes=False)
    if dragon_results and dragon_results[0].keypoints is not None:
        kpts = dragon_results[0].keypoints.xy.cpu().numpy()
        conf = dragon_results[0].keypoints.conf.cpu().numpy()
        if params['single_dragon'] and len(kpts) > 0:
            best = int(np.argmax(dragon_results[0].boxes.conf.cpu().numpy()))
            kpts, conf = kpts[best:best+1], conf[best:best+1]
        for i, kp_set in enumerate(kpts):
            for j, ((x, y), c) in enumerate(zip(kp_set, conf[i])):
                if c > params['confs'][3]:      # dragon_kpt_conf
                    color = params['node_colors'][j % len(params['node_colors'])]
                    cv2.circle(out, (int(x), int(y)), params['node_size'], color, -1)
            for (a, b) in DRAGON_SKELETON:
                if conf[i][a] > params['confs'][3] and conf[i][b] > params['confs'][3]:
                    pt1 = tuple(map(int, kp_set[a]))
                    pt2 = tuple(map(int, kp_set[b]))
                    cv2.line(out, pt1, pt2, params['line_color'], params['line_thickness'])

    # 4. åŠ¨ä½œåˆ†ç±»
    if params['classify'] and dragon_results:
        try:
            p_arr, d_arr = build_class_inputs(person_results, dragon_results, (out.shape[1], out.shape[0]))
            label = classify_action(st.session_state.classify_model_obj,
                                    st.session_state.classes,
                                    p_arr, d_arr, device)
            out = put_chinese_text(out, f"Action: {label}")
        except:
            pass

    return av.VideoFrame.from_ndarray(out, format="bgr24")

# ---------- Streamlit é¡µé¢ ----------
st.markdown("<h2 style='text-align:center'>ğŸ“¹ æµè§ˆå™¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹</h2>", unsafe_allow_html=True)
webrtc_streamer(
    key="dragon-camera",
    mode=WebRtcMode.SENDRECV,
    video_frame_callback=video_frame_callback,
    media_stream_constraints={"video": True, "audio": False},
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)
